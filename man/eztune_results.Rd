% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eztune_results.R
\name{eztune_results}
\alias{eztune_results}
\title{Performs a specified number of eztune results}
\usage{
eztune_results(
  x,
  y,
  data_name,
  method = NULL,
  optimizer = NULL,
  fast = NULL,
  cross = NULL,
  loss = NULL,
  iterations = 10,
  path = "."
)
}
\arguments{
\item{x}{Matrix or data frame containing the dependent variables.}

\item{y}{Vector of responses. Can either be a factor or a numeric vector.}

\item{data_name}{Name of the dataset. Used to name the output file and
as an identifier within the output dataset.}

\item{method}{Model to be fit. Choices are "ada" for adaboost, "en" for
elastic net, "gbm" for gradient boosting machines, and "svm" for support
vector machines.}

\item{optimizer}{Optimization method. Options are "ga" for a genetic
algorithm and "hjn" for a Hooke-Jeeves optimizer.}

\item{fast}{Indicates if the function should use a subset of the
observations when optimizing to speed up calculation time. A value of
TRUE will use the smaller of 50% of the data or 200 observations for
model fitting, a number between 0 and 1 specifies the proportion of
data to be used to fit the model, and a positive integer specifies the
number of observations to be used to fit the model. A model is computed
using a random selection of data and the remaining data are used to
validate model performance. The validation error measure is used as
the optimization criterion.}

\item{cross}{If an integer k > 1 is specified, k-fold cross-validation
is used to fit the model. This method is very slow for large datasets.
If it is "Resub" it will do resubstitution. This parameter is ignored
unless fast = FALSE.}

\item{loss}{The type of loss function used for optimization. Options for
models with a binary response are "class" for classification error and
"auc" for area under the curve. Options for models with a continuous
response are "mse" for mean squared error and "mae" for mean absolute
error. If the option "default" is selected, or no loss is specified,
the classification accuracy will be used for a binary response model
and the MSE will be use for models with a continuous model.}

\item{iterations}{Number of times to run the model.}

\item{path}{Where the file should be saved.}
}
\value{
Saves a matrix to the indicated path that contains the results
for each of the runs. The final file contains the following variables:

\item{data}{Name of the dataset.}
\item{method}{Type of model that was fit. It will an abbreviation
for adaboost, elastic net, gradient boosting machines, or
support vector machines.}
\item{optimizer}{Type of optimizer used. It will either be ga
for a genetic algorithm or hjn for a Hookes-Jeeves algorithm.}
\item{fast}{The argument passed to the fast option. If it is a 1,
a value of TRUE was passed and if it was 0 a value of FALSE was
passed.}
\item{cross}{n for n-fold cross-validation in the optimization. It
was only used if fast was FALSE.}
\item{loss_type}{Type of loss used as an optimizer. If the dataset has a
continuous response, the options are mse for mean squared error and
mae for mean absolute error. If the response is binary, the options
are acc for accuracy and auc for area under the ROC curve.}
\item{time}{Number of seconds to complete the calculations.}
\item{loss}{Loss value returned by eztune.}
\item{loss_mse_acc_10}{Estimate of the accuracy or mean squared error
as computed using the eztune_cv function with 10 fold cross validation.}
\item{loss_mae_auc_10}{Estimate of the area under the curve or mean absolute
error as computed using the eztune_cv function with 10 fold cross
validation.}
}
\description{
eztune_results runs eztune with the specified arguments. It saves
a matrix with the results.
}
\seealso{
\code{\link{load_opt_data}}, \code{\link{average_metric}}
}
